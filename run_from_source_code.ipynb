{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "### I will be using this jupyter notebook to run my local changes on the source code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load raw CSV -> Convert them to pickle form with {\"question_to_label\":[], \"answer_to_label\": []}\n",
    "# Save pickle form in format of <domain>_orignal.pkl where an example of <domain> is comcare/babybonus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Obtain the lists of questions and answers from any format, particularly from the pickle file\n",
    "\"\"\"\n",
    "import pickle\n",
    "\n",
    "def save_dict(obj, path):\n",
    "    # Save in .pickle format\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dict(path):\n",
    "    # Load .pickle format as dictionary\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "\n",
    "def extractQA(orignalDct):\n",
    "    # Return list of questions and answers in list format\n",
    "    # originalDct format: {\"question_to_label\": {<question 1>: <label that maps to answer>,...}, \n",
    "    #                      \"answer_to_label\": {<answer question 1>: <label for questions to be mapped to>}}\n",
    "    # Handles 1-1 mapping of question-answer OR many-1 mapping of question-answer\n",
    "    q2L = orignalDct[\"question_to_label\"]\n",
    "    a2L = orignalDct[\"answer_to_label\"]\n",
    "    \n",
    "\n",
    "    l2A = dict()\n",
    "    for a,l in a2L.items():\n",
    "        l2A[l] = a\n",
    "\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q,l in q2L.items():\n",
    "        questions.append(q)\n",
    "        answers.append(l2A[l])\n",
    "    return questions , answers\n",
    "\n",
    "def visualize_question_answer(questions, answers, show_pairs = 5):\n",
    "    count = 1\n",
    "    for question, answer in zip(questions, answers):\n",
    "        print(f\"Question {count}: {question}\\n\\n'{answer}''\")\n",
    "        print(\"=\"*117)\n",
    "        count += 1\n",
    "        if count > show_pairs:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Convert parallel lists of questions and answers to CSVs for dialogflow or Bani\n",
    "\"\"\"\n",
    "import csv\n",
    "\n",
    "def convert_pickle_to_csv(questions, answers, file_name = \"new.csv\", is_bani = True):\n",
    "    # Take in lists of question and answer where question-answer pair have the same index in both lists\n",
    "    # Read each question-answer pair into csv\n",
    "    with open(file_name, mode='w') as new_csv:\n",
    "        csv_writer = csv.writer(new_csv, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "\n",
    "        count = 0\n",
    "        for question, answer in zip(questions, answers):\n",
    "            if is_bani:\n",
    "                csv.writer.writerow([count, question, answer])\n",
    "                count += 1\n",
    "            else:\n",
    "                # Format for dialogflow\n",
    "                csv_writer.writerow([question, answer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'load_dict' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c001b608dae0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mresultFAQ\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m \u001b[0mbabyBonusFAQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_faq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./tutorialFAQs/baby_bonus_orignal.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"babyBonus\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m \u001b[0mcomcareFAQ\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_faq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"./tutorialFAQs/comcare_orignal.pkl\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"comcare\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-1-c001b608dae0>\u001b[0m in \u001b[0;36mget_faq\u001b[0;34m(dict_path, name, generator)\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0moutput\u001b[0m \u001b[0mFAQ\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m     \"\"\"\n\u001b[0;32m---> 12\u001b[0;31m     \u001b[0moriginal_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdict_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m     \u001b[0mquestions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0manswers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mextractQA\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moriginal_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_dict' is not defined"
     ]
    }
   ],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "from Bani.core.defaults import defaultGenerateManager\n",
    "\n",
    "def get_faq(dict_path, name, generator):\n",
    "    \"\"\"\n",
    "    @param dict_path: str -> relative path to .pkl file with keys \"question_to_label\" and \"answer_to_label\"\n",
    "    @param name: str -> Name of FAQ\n",
    "    @param generator: GenerateManager -> Generator pipeline for augmenting questions. Set to none if not augmenting\n",
    "    @output FAQ object\n",
    "    \"\"\"\n",
    "    original_dict = load_dict(dict_path)\n",
    "    questions, answers = extractQA(original_dict)\n",
    "    \n",
    "    resultFAQ = FAQ(name = name, questions = questions, answers = answers)\n",
    "    if generator:\n",
    "        resultFAQ.buildFAQ(generator = generator)\n",
    "    else:\n",
    "        resultFAQ.buildFAQ(generator = None)\n",
    "    return resultFAQ\n",
    "\n",
    "babyBonusFAQ = get_faq(dict_path = \"./tutorialFAQs/baby_bonus_orignal.pkl\", name = \"babyBonus\", generator = None)\n",
    "comcareFAQ = get_faq(dict_path = \"./tutorialFAQs/comcare_orignal.pkl\", name = \"comcare\", generator = None)\n",
    "\n",
    "\"\"\"\n",
    "@param modelPath = None -> Download a pretrained model of the SentenceTransformers\n",
    "@param assignVectors = True -> Assign vectors accordingly. \n",
    "@param FAQs: List of FAQ object\n",
    "\"\"\"\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)\n",
    "\n",
    "# bot.train(\"./checkpoints/dummy\", lossName = \"softmaxLayerLos1s\", batchSize = 8, warmst)\n",
    "\n",
    "# TODO: Convert FAQ object back to CSV\n",
    "\n",
    "# Optional: Save FAQ\n",
    "# babyBonusFAQ.save(\"./jamesFAQs/no_generate\")\n",
    "# comcareFAQ.save(\"./jamesFAQs/no_generate\")\n",
    "\n",
    "# Optional: Load FAQ\n",
    "# babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "# babyBonusFAQ.load(\"./jamesFAQs/no_generate\")\n",
    "\n",
    "# comcareFAQ = FAQ(\"comcare\")\n",
    "# comcareFAQ.load(\"./faqStore/no_generate\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name must correspond to the .pkl file name. i.e. name = babyBonus, .pkl file = babyBonus.pkl\n",
    "testFAQ = FAQ(name = \"babyBonus\")\n",
    "testFAQ.load(\"./jamesFAQs/no_generate\")\n",
    "\n",
    "name = testFAQ.name\n",
    "questions = testFAQ.questions\n",
    "answers = testFAQ.answers\n",
    "l2Q = testFAQ.l2Q\n",
    "l2A = testFAQ.l2A\n",
    "FAQ_units = testFAQ.FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'how can my organisation apply to be a baby bonus approved institution? 0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "FAQ_units[0].orignal.__str__()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Inspection of Augmented Questions for their Semantic Integrity/Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Name: SymSub\n",
      "Picking 3 questions\n",
      "Producer Name: Sense-disambiguated Synonym Substitution\n",
      "Producer's dir:\n",
      " ['_get_synonyms', 'batch_generate', 'discount_factor', 'encoder', 'generate', 'name', 'threshold']\n",
      "===================================================================================================================\n",
      "\n",
      "Generator Name: FPM\n",
      "Picking 3 questions\n",
      "Producer Name: Fuzzy Question Pattern Matching\n",
      "Producer's dir:\n",
      " ['_format_output', '_generate_patterns', '_has_multiple_question', '_preprocess', '_split_question', 'batch_generate', 'generate', 'matcher', 'name', 'patterns']\n",
      "===================================================================================================================\n",
      "\n",
      "Generator Name: EDA\n",
      "Picking 3 questions\n",
      "Producer Name: Easy Data Augmentation Techniques\n",
      "Producer's dir:\n",
      " ['_get_only_chars', '_get_synonyms', '_random_deletion', '_random_insertion', '_random_swap', '_swap_word', '_synonym_replacement', 'alpha_ri', 'alpha_rs', 'alpha_sr', 'batch_generate', 'generate', 'name', 'num_aug', 'p_rd']\n",
      "===================================================================================================================\n",
      "\n",
      "Generator Name: nlpAug\n",
      "Picking 2 questions\n",
      "*No known producer name*\n",
      "Producer's dir:\n",
      " ['augs', 'exact_batch_generate']\n",
      "===================================================================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Inspecting defaultGenerateManager's generators and their corresponding producer\n",
    "\n",
    "From the output, you will notice:\n",
    "1. Different producers have their own properties and methods\n",
    "2. nlpAug generator's producer have no \"name\" property\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n",
    "\n",
    "for i in range(len(defaultGenerateManager.generators)):\n",
    "    generator = defaultGenerateManager.generators[i]\n",
    "    producer = generator.producer\n",
    "    print(f\"Generator Name: {generator.name}\")\n",
    "    print(f\"Picking {generator.num} questions\")\n",
    "    if \"name\" in dir(producer):\n",
    "        print(f\"Producer Name: {producer.name}\")\n",
    "    else:\n",
    "        print(\"*No known producer name*\")\n",
    "    print(f\"Producer's dir:\\n {dir(producer)[27:]}\")\n",
    "    print(\"=\"*115 + \"\\n\")\n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 70/70 [00:06<00:00, 10.96it/s]\n",
      "100%|██████████| 215/215 [00:19<00:00, 11.04it/s]\n",
      "100%|██████████| 191/191 [00:16<00:00, 11.58it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Pass in original questions, and generate their corresponding augmented questions for inspection in subsequent cells\n",
    "You may pass in only selected number of original questions e.g. questions[:3] to choose 3 questions\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n",
    "from collections import defaultdict\n",
    "\n",
    "original_dict = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\")\n",
    "questions, answers = extractQA(original_dict)\n",
    "\n",
    "symsub_producer = defaultGenerateManager.generators[0].producer\n",
    "fpm_producer = defaultGenerateManager.generators[1].producer\n",
    "eda_producer = defaultGenerateManager.generators[2].producer\n",
    "nlpAug_producer = defaultGenerateManager.generators[3].producer\n",
    "\n",
    "result_symsub = defaultdict(list)\n",
    "result_fpm = defaultdict(list)\n",
    "result_eda = defaultdict(list)\n",
    "result_nlpAug = defaultdict(list)\n",
    "for question in questions[:3]:\n",
    "    result_symsub[question] = symsub_producer.generate(question)\n",
    "    result_fpm[question] = fpm_producer.generate(question)\n",
    "    result_eda[question] = eda_producer.generate(question)    \n",
    "    result_nlpAug[question] = nlpAug_producer.exact_batch_generate(question,3)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original question: \n",
      "I have entered the Unique Entity Number (UEN) using 'Join as an Approved Institution (AI)' service, but your system does not have matching records of my Unique Entity Number (UEN). Can I still submit my application?\n"
     ]
    }
   ],
   "source": [
    "print(f\"Original question: \\n{questions[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "575"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_symsub[questions[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(result_fpm[questions[1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i have entered the unique entity number uen using join as an ok foundation ai service but your system does not have matching register of my unique entity number uen can i still submit my application',\n",
       " 'entered the unique entity number uen join as an approved institution ai service but your system does not have matching records of my unique entity number uen can i still submit my application',\n",
       " 'i three toed sloth have entered the unique entity number uen using join alone as an approved institution ai service but your associate in nursing system does not have matching records of my unique entity number uen can i still submit my application',\n",
       " 'i have entered the okay unique okeh entity number uen using robert william service join as an approved institution ai service but your system does not have matching records of my unique entity number uen can i still submit my application',\n",
       " 'not have entered the unique entity number uen using my as service approved institution ai an but your system does i have matching records of my unique entity number uen can i still submit join application',\n",
       " 'i have entered the unique entity number uen using join as an approved institution alone ai service but your system alone does not have matching records of my unique entity number uen can i a still submit my application',\n",
       " 'i have entered the unique entity number my using join as records approved institution ai service but your system does not have matching an of my unique entity number application can i still submit uen uen',\n",
       " 'i have entered the unique entity number uen using join as an approved institution ai service but your system does not have rival records of my unique entity number uen can i silent submit my diligence',\n",
       " 'i have entered the alone entity number uen using bring together as an approved institution ai service but your system of rules does not have matching records of my alone entity number uen can i still submit my application',\n",
       " 'i have entered the unique entity number uen using join as an approved institution ai service but your system does not have matching records of my unique entity number uen can i still submit my application ']"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_eda[questions[1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['H', 'o', 'w', ' ', 'c', 'a', 'n', 'm', 'y', 'r', 'g', 'i', 's', 't', 'p', 'l', 'b', 'e', 'B', 'u', 'A', 'v', 'd', 'I', '?'])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_nlpAug[questions[0]].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "863\n",
      "12\n",
      "10\n",
      "33\n"
     ]
    }
   ],
   "source": [
    "QUESTION_NUM = 2\n",
    "print(len(result_symsub[questions[QUESTION_NUM]]))\n",
    "print(len(result_fpm[questions[QUESTION_NUM]]))\n",
    "print(len(result_eda[questions[QUESTION_NUM]]))\n",
    "print(len(result_nlpAug[questions[QUESTION_NUM]]))                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# name must correspond to the .pkl file name. i.e. name = babyBonus, .pkl file = babyBonus.pkl\n",
    "babyBonusBani = FAQ(name = \"babyBonus\")\n",
    "babyBonusBani.load(\"./faqStore\")\n",
    "\n",
    "babyBonus_name = babyBonusBani.name\n",
    "babyBonus_questions = babyBonusBani.questions\n",
    "babyBonus_answers = babyBonusBani.answers\n",
    "babyBonus_l2Q = babyBonusBani.l2Q\n",
    "babyBonus_l2A = babyBonusBani.l2A\n",
    "babyBonus_FAQ_units = babyBonusBani.FAQ\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(babyBonus_FAQ_units[27].orignal.__str__())\n",
    "print(babyBonus_FAQ_units[27].label)\n",
    "print(dir(babyBonus_FAQ_units[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Question 1: How can my organisation apply to be a Baby Bonus Approved Institution?\n",
      "\n",
      "\n",
      "'Apply to be a Baby Bonus Approved Institution?''\n",
      "=====================================================================================================================\n",
      "Question 2: I have entered the Unique Entity Number (UEN) using 'Join as an Approved Institution (AI)' service, but your system does not have matching records of my Unique Entity Number (UEN). Can I still submit my application?\n",
      "\n",
      "\n",
      "'I have entered a UEN using the 'Join an AI' service, but my system does not have a matching record of my UEN. Can I still submit my application?''\n",
      "=====================================================================================================================\n",
      "Question 3: I have entered the Unique Entity Number (UEN) using the 'Join as Approved Institution (AI)' service, but your system indicated that my Unique Entity Number (UEN) is invalid, what should I do?\n",
      "\n",
      "\n",
      "'My UEN is showing as invalid. What shoud I do?''\n",
      "=====================================================================================================================\n",
      "Question 4: Is there a validity period to be a Baby Bonus Approved Institution?\n",
      "\n",
      "\n",
      "'Validity period to be a Baby Bonus AI?\n",
      "''\n",
      "=====================================================================================================================\n",
      "Question 5: How much does an organisation need to pay to register as an Approved Institution (AI) with Ministry of Social and Family Development (MSF)?\n",
      "\n",
      "\n",
      "'How much should my organisation pay to be registered as an AI withMMSF? ''\n",
      "=====================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "visualize_question_answer(df[\"original\"].tolist(), df[\"reframed\"].tolist())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
