{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Bani\n",
    "import sys\n",
    "from typing import List,Tuple,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsys.path.append('./')\\nsys.path.append('./core')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending paths as this is a jupyter notebook, if you want to use from the source code !!!\n",
    "\"\"\"\n",
    "sys.path.append('./')\n",
    "sys.path.append('./core')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is optional, we read the data from any faq here\n",
    "In this case we use the orignal faq pickle files , you may use\n",
    "csv or any other format !!!\n",
    "\n",
    "\n",
    "THE goal here is to get a list of questions and corosponding answers\n",
    "\"\"\"\n",
    "import pickle\n",
    "def save_dict(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dict(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def extractQA(orignalDct):\n",
    "    \"\"\"\n",
    "    Just returns the questions and answers in a list , \n",
    "    NOthing fancy\n",
    "    \"\"\"\n",
    "    q2L = orignalDct[\"question_to_label\"]\n",
    "    a2L = orignalDct[\"answer_to_label\"]\n",
    "    \n",
    "\n",
    "    l2A = dict()\n",
    "    for a,l in a2L.items():\n",
    "        l2A[l] = a\n",
    "\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q,l in q2L.items():\n",
    "        questions.append(q)\n",
    "        answers.append(l2A[l])\n",
    "    return questions , answers\n",
    "    \n",
    "\n",
    "babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "\n",
    "b_questions , b_answers = extractQA(babyBonusOrignal)\n",
    "c_questions , c_answers = extractQA(comcareOrignal)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOw the real work starts , We have question answer pairs from \n",
    "baby bonus and comcare , We need to create a new faq for both of them\n",
    "\n",
    "NOTE - This is the starting point , we need a LIst of questions and a list of answers\n",
    "THE LENGTH OF BOTH LIST MUST BE SAME\n",
    "if two questions answer the same questions then just copy the answer \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# first we convert the questions and answers to FAQs\n",
    "babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Until this point we only have the orignal questions and answers in the faq\n",
    "We now need to do two things\n",
    "1) generate questions using pipelined\n",
    "2) assign vectors to the questions using a model  \n",
    "\n",
    "\n",
    "you can use your own generation pipeline , or use the default pipeline provided !!!\n",
    "if you choose to implement your own pipeline make sure that your class implements at least one of \n",
    "batch_generate or exact_batch_generate methods\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an example of creating your own GenerateManager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from Bani.core.generation import GenerateManager\n",
    "\n",
    "class MyProducer1:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "class MyProducer2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "    \n",
    "names = [\"myProducer1_name\", \"myProducer2_name\"]\n",
    "toGenerate = [3,5] # At max generate 3 for first producer and 5 for second\n",
    "producers = [MyProducer1(), MyProducer2()]\n",
    "\n",
    "\n",
    "myGenerateManager = GenerateManager(producers = producers , names = names , nums = toGenerate)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with IdentityProducer pipeline\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Now we will build the FAQ using the generationManager\n",
    "This will generate paraphrases of the questions using the pipeline given\n",
    "\n",
    "you can also leave the generator argument as none ,\n",
    "In this case you wont be generating any questions, but then you cant train using a \n",
    "batch hard triple loss as well !!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [01:28<00:00,  3.27it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [05:05<00:00,  1.06s/it]\n",
      " 11%|████████▉                                                                       | 32/288 [00:00<00:00, 319.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 288/288 [00:00<00:00, 295.96it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [04:32<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "comcareFAQ.buildFAQ(generator  = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can save the FAQ at any time we want !! , just pass the path to the root dir \n",
    "\"\"\"\n",
    "babyBonusFAQ.save(\"./faqStore\")\n",
    "comcareFAQ.save(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The saved FAQ can be easily loaded \n",
    "\"\"\"\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjkin\\Desktop\\BaniPackage\\Bani\\Bani.py:131: UserWarning: Vectors already assigned to babyBonus FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\n",
      "  warnings.warn(\"Vectors already assigned to {} FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\".format(faq.name))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lets now take a look at the bot part, for assignVectors refer to the readme\n",
    "\"\"\"\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ], assignVectors = False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can also save the FAQ again to preserve the assigned vectors ,\n",
    "The next time you load these FAQs with the bot the vectors will not be reassigned ,\n",
    "You need to clear the assigned vectors if you want to reassign\n",
    "\"\"\"\n",
    "bot.saveFAQs(\"./faqStore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "out is a list of FAQ output , each output for each FAQ\n",
    "compare the score field in each to get the highest scored FAQ, \n",
    "you can also set a margin of error and ask the user to decide between the faq\n",
    "\n",
    "\"\"\"\n",
    "out = bot.findClosest(\"what is comcare scheme?\", K = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faqName - babyBonus\n",
      "\n",
      "answer - The Child Development Account (CDA) trustee, can be either a parent or a third party nominated by the child’s parents as declared to MSF. Both parents must agree to the nomination. The CDA trustee’s responsibility is to ensure the proper usage of CDA funds for the benefit of the child. The CDA trustee must not be bankrupt, and must be above 18 years of age.\n",
      "\n",
      "question - Who can be the Child Development Account (CDA) Trustee?\n",
      "\n",
      "maxScore - 0.5368013978004456\n",
      "\n",
      "score - 1.5918986797332764\n",
      "\n",
      "==================================================\n",
      "\n",
      "['What is a Child Development Credit or CDA top-up?', 'What is the Child Development Co-Savings Scheme?', 'How can I identify an Approved Institution for the use of Child Development Account (CDA) funds?', 'How do Approved institutions collect fees from the Child Development Account (CDA)?', 'What is the Child Development Account (CDA)?']\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding answer from a specific FAQ\n",
    "\"\"\"\n",
    "out = bot.findClosestFromFAQ(0,\"eligliblity for baby bonus for my child?\", K = 3, topSimilar= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faqName - babyBonus\n",
      "\n",
      "answer - You can check your child’s eligibility and Baby Bonus Benefits on Baby Bonus Online using “Check Eligibility”.    Alternatively, you can let us know which date your child is born to help us answer your question. Born on or after 24 March 2016 Please select your child birth order. You may wish to know that the birth order of the child is tied to his or her birth mother. A stillbirth is counted as a birth order. Non-citizen children and stepchildren are not considered in the counting of birth orders. First and Second Goes to MQA BBB - after 24 Mar 2016 - First and Second Third and Fourth Goes to MQA BBB - after 24 Mar 2016 – Third and Fourth Fifth and beyond Goes to MQA BBB - after 24 Mar 2016 – Fifth and Beyond Born on 1 January 2015 to 23 March 2016 Please select your child birth order. You may wish to know that the birth order of the child is tied to his or her birth mother. A stillbirth is counted as a birth order. Non-citizen children and stepchildren are not considered in the counting of birth orders. First and Second Goes to MQA BBB - 1 Jan 2015 to 23 Mar 2016 - First and Second Third and Fourth Goes to MQA BBB - 1 Jan 2015 to 23 Mar 2016 - Third and Fourth Fifth and beyond Goes to MQA BBB - 1 Jan 2015 to 23 Mar 2016 - Fifth and Beyond   Born on 26 August 2012 to 31 December 2014 Please select your child birth order. You may wish to know that the birth order of the child is tied to his or her birth mother. A stillbirth is counted as a birth order. Non-citizen children and stepchildren are not considered in the counting of birth orders. First and Second Goes to MQA BBB - 26 Aug 2012 to 31 Jan 2014 - First and Second Third and Fourth Goes to MQA BBB - 26 Aug 2012 to 31 Jan 2014 - Third and Fourth Fifth and beyond Goes to MQA BBB - 26 Aug 2012 to 31 Jan 2014 - Fifth and Beyond Born on 17 August 2008 to 25 August 2012 Please select your child birth order. You may wish to know that the birth order of the child is tied to his or her birth mother. A stillbirth is counted as a birth order. Non-citizen children and stepchildren are not considered in the counting of birth orders. First and Second Goes to BBB - 17 Aug 2008 to 25 Aug 2012 - First and Second Third and Fourth Goes to BBB - 17 Aug 2008 to 25 Aug 2012 - Third and Fourth Fifth and beyond Goes to BBB - 17 Aug 2008 to 25 Aug 2012 - Fifth and Beyond Born on 1 January 2006 to 16 August 2008 Please select your child birth order. You may wish to know that the birth order of the child is tied to his or her birth mother. A stillbirth is counted as a birth order. Non-citizen children and stepchildren are not considered in the counting of birth orders. First Goes to MQA BBB - 1 Jan 2006 to 16 Aug 2008 - First Second Goes to MQA BBB - 1 Jan 2006 to 16 Aug 2008 - Second Third and Fourth Goes to MQA BBB - 1 Jan 2006 to 16 Aug 2008 - Third and Fourth\n",
      "\n",
      "question - What are the Baby Bonus Benefits for my child?\n",
      "\n",
      "maxScore - 0.8097913265228271\n",
      "\n",
      "score - 2.394968032836914\n",
      "\n",
      "==================================================\n",
      "\n",
      "['Is my child eligible for the Baby Bonus Scheme?', 'What can I use the Baby Bonus cash gift for?', 'What is a Baby Bonus Approved Institution?', 'I have applied for the Baby Bonus Scheme. How can I open a Child Development Account (CDA) for my child?', 'What is Baby Bonus scheme?']\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec2703f9caeb4ebdb03f59ace844c47e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0233b47def9049caaed9c2e3e19f6fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=420.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-11-0e5d9741ecbb>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mare\u001b[0m \u001b[0mbatchHardTriplet\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontrastiveLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./checkpoints/dummy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"softmaxLayerLoss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\BaniPackage\\Bani\\Bani.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, outputPath, batchSize, epochs, lossName, **kwargs)\u001b[0m\n\u001b[0;32m    238\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_objectives\u001b[0m\u001b[1;33m=\u001b[0m  \u001b[0mtrainingObjectives\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwarmup_steps\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msave_best_model\u001b[0m\u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0moutput_path\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0moutputPath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 240\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msaveModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    241\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSentenceTransformer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutputPath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfaq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAQs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\sentence_transformers\\SentenceTransformer.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, train_objectives, evaluator, epochs, steps_per_epoch, scheduler, warmup_steps, optimizer_class, optimizer_params, weight_decay, evaluation_steps, output_path, save_best_model, max_grad_norm, use_amp, callback, output_path_ignore_not_empty)\u001b[0m\n\u001b[0;32m    579\u001b[0m                         \u001b[0mloss_value\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    580\u001b[0m                         \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclip_grad_norm_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mloss_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_grad_norm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 581\u001b[1;33m                         \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    582\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    583\u001b[0m                     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\torch\\optim\\lr_scheduler.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m                 \u001b[0minstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_step_count\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m                 \u001b[0mwrapped\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__get__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minstance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcls\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mwrapped\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m             \u001b[1;31m# Note that the returned function here is no longer a bound method,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python36\\lib\\site-packages\\transformers\\optimization.py\u001b[0m in \u001b[0;36mstep\u001b[1;34m(self, closure)\u001b[0m\n\u001b[0;32m    293\u001b[0m                 \u001b[1;31m# Decay the first and second moment running average coefficient\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m                 \u001b[1;31m# In-place operations to update the averages at the same time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m                 \u001b[0mexp_avg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m                 \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maddcmul_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1.0\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mbeta2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m                 \u001b[0mdenom\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexp_avg_sq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"eps\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Look at the documentation for train , and set all the arguments accordingly,\n",
    "if you have not run the buildFAQ , then you cannot train on most of the losses !!! \n",
    "losses available are batchHardTriplet and contrastiveLoss\n",
    "\"\"\"\n",
    "bot.train(\"./checkpoints/dummy\", lossName = \"softmaxLayerLoss\", batchSize = 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing requires a list of (questions , reframed_question) to be passed and returns the accuracy score \n",
    "you can test one faq at a time\n",
    "\"\"\"\n",
    "bot.test(faqId = 0, testData = testData, K = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceLabelDataset, SentencesDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Bani.modelRelated.utils import convertForBatchHardTripletLoss\n",
    "from Bani.modelRelated.lossHandler import LossHandler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = convertForBatchHardTripletLoss(babyBonusFAQ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
