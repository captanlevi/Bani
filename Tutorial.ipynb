{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: Bani 0.6\n",
      "Uninstalling Bani-0.6:\n",
      "  Would remove:\n",
      "    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/Bani-0.6.dist-info/*\n",
      "    /Library/Frameworks/Python.framework/Versions/3.7/lib/python3.7/site-packages/Bani/*\n",
      "Proceed (y/n)? ^C\n",
      "\u001B[31mERROR: Operation cancelled by user\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install Bani"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is optional, we read the data from any faq here\n",
    "In this case we use the orignal faq pickle files , you may use\n",
    "csv or any other format !!!\n",
    "\n",
    "\n",
    "THE goal here is to get a list of questions and corosponding answers\n",
    "\"\"\"\n",
    "import pickle\n",
    "def save_dict(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dict(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def extractQA(orignalDct):\n",
    "    \"\"\"\n",
    "    Just returns the questions and answers in a list , \n",
    "    NOthing fancy\n",
    "    \"\"\"\n",
    "    q2L = orignalDct[\"question_to_label\"]\n",
    "    a2L = orignalDct[\"answer_to_label\"]\n",
    "    \n",
    "\n",
    "    l2A = dict()\n",
    "    for a,l in a2L.items():\n",
    "        l2A[l] = a\n",
    "\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q,l in q2L.items():\n",
    "        questions.append(q)\n",
    "        answers.append(l2A[l])\n",
    "    return questions , answers\n",
    "    \n",
    "babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "b_questions , b_answers = extractQA(babyBonusOrignal)  # list of questions and answers \n",
    "c_questions , c_answers = extractQA(comcareOrignal)    # list of questions and answers "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now the real work starts , We have question answer pairs from \n",
    "baby bonus and comcare , We need to create a new faq for both of them\n",
    "\n",
    "NOTE - This is the starting point , we need a list of questions and a list of answers\n",
    "THE LENGTH OF BOTH LIST MUST BE SAME\n",
    "if two questions answer the same questions then just copy the answer \n",
    "\"\"\"\n",
    "\n",
    "# first we convert the questions and answers to FAQs\n",
    "babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Until this point we only have the orignal questions and answers in the faq\n",
    "We now need to do two things\n",
    "1) generate questions using pipeline\n",
    "2) assign vectors to the questions using a model  \n",
    "\n",
    "\n",
    "you can use your own generation pipeline , or use the default pipeline provided !!!\n",
    "if you choose to implement your own pipeline make sure that your class implements at least one of \n",
    "batch_generate or exact_batch_generate methods\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'List' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-21-17471482e21b>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m      6\u001B[0m \u001B[0;32mfrom\u001B[0m \u001B[0mBani\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mcore\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mgeneration\u001B[0m \u001B[0;32mimport\u001B[0m \u001B[0mGenerateManager\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m      7\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m----> 8\u001B[0;31m \u001B[0;32mclass\u001B[0m \u001B[0mMyProducer1\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m      9\u001B[0m     \u001B[0;32mdef\u001B[0m \u001B[0m__init__\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m<ipython-input-21-17471482e21b>\u001B[0m in \u001B[0;36mMyProducer1\u001B[0;34m()\u001B[0m\n\u001B[1;32m     10\u001B[0m         \u001B[0;32mpass\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     11\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 12\u001B[0;31m     \u001B[0;32mdef\u001B[0m \u001B[0mbatch_generate\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mquestions\u001B[0m \u001B[0;34m:\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m)\u001B[0m \u001B[0;34m->\u001B[0m \u001B[0mDict\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mList\u001B[0m\u001B[0;34m[\u001B[0m\u001B[0mstr\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m]\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     13\u001B[0m         \"\"\"\n\u001B[1;32m     14\u001B[0m         \u001B[0mTakes\u001B[0m \u001B[0mlist\u001B[0m \u001B[0mof\u001B[0m \u001B[0mquestions\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mreturns\u001B[0m \u001B[0ma\u001B[0m \u001B[0mdict\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0;32mwith\u001B[0m \u001B[0meach\u001B[0m \u001B[0mquestion\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'List' is not defined"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This is an example of creating your own GenerateManager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from Bani.core.generation import GenerateManager\n",
    "\n",
    "class MyProducer1:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "class MyProducer2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def generate(self, sentence):\n",
    "        # Implement your generation of questions for a given sentence\n",
    "        # Return a list\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = self.generate(sentence)\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "    \n",
    "names = [\"myProducer1_name\", \"myProducer2_name\"]\n",
    "toGenerate = [3,5] # At max generate 3 for first producer and 5 for second\n",
    "producers = [MyProducer1(), MyProducer2()]\n",
    "\n",
    "\n",
    "myGenerateManager = GenerateManager(producers = producers , names = names , nums = toGenerate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with IdentityProducer pipeline\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Now we will build the FAQ using the generationManager\n",
    "This will generate paraphrases of the questions using the pipeline given\n",
    "\n",
    "you can also leave the generator argument as none ,\n",
    "In this case you wont be generating any questions, but then you cant train using a \n",
    "batch hard triple loss as well !!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)\n",
    "babyBonusFAQ.buildFAQ(generator = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with IdentityProducer pipeline\n"
     ]
    }
   ],
   "source": [
    "# comcareFAQ.buildFAQ(generator  = defaultGenerateManager)\n",
    "comcareFAQ.buildFAQ(generator  = None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can save the FAQ at any time we want !! , just pass the path to the root dir \n",
    "\"\"\"\n",
    "babyBonusFAQ.save(\"./faqStore\")\n",
    "comcareFAQ.save(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The saved FAQ can be easily loaded \n",
    "\"\"\"\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverWritting the vectors of FAQ named babyBonus , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "OverWritting the vectors of FAQ named comcare , it will name save the generated vectors , to do that use the saveFAQ/s feature\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lets now take a look at the bot part, for assignVectors refer to the readme\n",
    "JR: If modelPath is None, download a pretrained model of the SentenceTransformer\n",
    "\"\"\"\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can also save the FAQ again to preserve the assigned vectors ,\n",
    "The next time you load these FAQs with the bot the vectors will not be reassigned ,\n",
    "You need to clear the assigned vectors if you want to reassign\n",
    "\"\"\"\n",
    "bot.saveFAQs(\"./faqStore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "out is a list of FAQ output , each output for each FAQ\n",
    "compare the score field in each to get the highest scored FAQ, \n",
    "you can also set a margin of error and ask the user to decide between the faq\n",
    "\n",
    "\"\"\"\n",
    "out = bot.findClosest(\"What is the foreign domestic worker (FDW) grant?\", K = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bani.core.FAQ.FAQOutput at 0x7fbad53611d0>,\n",
       " <Bani.core.FAQ.FAQOutput at 0x7fbad5309fd0>]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'faqId'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-25-d847e0978753>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[0;32m----> 1\u001B[0;31m \u001B[0mprint\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfaqId\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mout\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mfaqName\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[0;31mAttributeError\u001B[0m: 'list' object has no attribute 'faqId'"
     ]
    }
   ],
   "source": [
    "print(out.faqId, out.faqName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding answer from a specific FAQ\n",
    "\"\"\"\n",
    "out = bot.findClosestFromFAQ(1,\"eligliblity for baby bonus for my child?\", K = 3, topSimilar= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faqName - babyBonus\n",
      "\n",
      "answer - If your spouse is a foreigner, when filling in the Baby Bonus application form, you should  Leave the “NRIC/FIN” field blank Select “Passport Number” or “Foreign ID” for “Identification Type”, and Enter his or her latest passport number at “Passport Number/Foreign ID” field.  \n",
      "\n",
      "question - My spouse is a foreigner. How should I complete his/her details in the application form?\n",
      "\n",
      "maxScore - 0.5470118522644043\n",
      "\n",
      "score - 2.6833885312080383\n",
      "\n",
      "==================================================\n",
      "\n",
      "['What other benefits can unwed parents qualify for?', 'How much does an organisation need to pay to register as an Approved Institution (AI) with Ministry of Social and Family Development (MSF)?', 'Why does my spouse need to log in with SingPass as well? Can I submit the application on my spouseâ€™s behalf?', 'Is there a limit to the number of Child Development Accounts per family?', 'How do I receive the Baby Bonus letters from Ministry of Social and Family Development (MSF) if I am overseas?']\n"
     ]
    }
   ],
   "source": [
    "print(out[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Look at the documentation for train , and set all the arguments accordingly,\n",
    "if you have not run the buildFAQ , then you cannot train on most of the losses !!! \n",
    "losses available are batchHardTriplet and contrastiveLoss\n",
    "\"\"\"\n",
    "bot.train(\"./checkpoints/dummy\", lossName = \"softmaxLayerLos1s\", batchSize = 8, warmst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/Projects/Bani/Bani/Bani.py:204: UserWarning: 3 questions in the test set did not match any orignal questions\n",
      "  warnings.warn(\"{} questions in the test set did not match any orignal questions\".format(len(nonMatched)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test on 291 questions\n",
      "0.9140893470790378 with 266 out of 291 questions correct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "testing requires a list of (question , reframed_question) to be passed and returns the accuracy score \n",
    "you can test one faq at a time\n",
    "\"\"\"\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing Bani with different datasets (augmented or original FAQs) with or without training (James) to explore the effects of using augmented FAQs and performing model training for transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverWritting the vectors of FAQ named babyBonus , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "OverWritting the vectors of FAQ named comcare , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "Running test on 291 questions\n",
      "0.9140893470790378 with 266 out of 291 questions correct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test with augmented FAQs (w/o training)\n",
    "\"\"\"\n",
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "import pandas as pd\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")\n",
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")\n",
    "\n",
    "# Initialize Bani\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)\n",
    "\n",
    "# Do I need to run this?\n",
    "# bot.train(outputPath = \"./checkpoints/dummy\", lossName = \"batchHardTriplet\", batchSize = 64)\n",
    "\n",
    "# Prepare test data\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))\n",
    "\n",
    "# Begin test\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverWritting the vectors of FAQ named babyBonus , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "OverWritting the vectors of FAQ named comcare , it will name save the generated vectors , to do that use the saveFAQ/s feature\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f62e6ba14d14577bb2cbead6904e628",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7b2c041c8e204b05926c34ab425c0e90",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=53.0, style=ProgressStyle(description_wid…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Assigning vectors from the trained model to FAQ babyBonus\n",
      "Assigning vectors from the trained model to FAQ comcare\n",
      "Running test on 291 questions\n",
      "0.9072164948453608 with 264 out of 291 questions correct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test with augmented FAQs (with training via batchHardTriplet)\n",
    "\"\"\"\n",
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "import pandas as pd\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")\n",
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")\n",
    "\n",
    "# Initialize Bani\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)\n",
    "\n",
    "# Do I need to run this?\n",
    "bot.train(outputPath = \"./checkpoints/dummy\", lossName = \"batchHardTriplet\", batchSize = 64,epochs=1)\n",
    "\n",
    "# Prepare test data\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))\n",
    "\n",
    "# Begin test\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n",
      "Initializing spaCy model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:10<00:00, 28.19it/s]\n",
      "  0%|          | 0/290 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [01:51<00:00,  2.60it/s]\n",
      " 20%|██        | 58/290 [00:00<00:00, 577.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [00:00<00:00, 687.82it/s]\n",
      "  0%|          | 0/290 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 290/290 [03:50<00:00,  1.26it/s]\n",
      "  0%|          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [00:30<00:00,  9.53it/s]\n",
      "  0%|          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [01:52<00:00,  2.57it/s]\n",
      " 21%|██        | 60/288 [00:00<00:00, 593.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [00:00<00:00, 776.12it/s]\n",
      "  0%|          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 288/288 [03:45<00:00,  1.28it/s]\n"
     ]
    }
   ],
   "source": [
    "from Bani.core.defaults import defaultGenerateManager\n",
    "babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "b_questions , b_answers = extractQA(babyBonusOrignal)  # list of questions and answers \n",
    "c_questions , c_answers = extractQA(comcareOrignal)    # list of questions and answers \n",
    "babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)\n",
    "\n",
    "babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)\n",
    "comcareFAQ.buildFAQ(generator = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning vectors to babyBonus faq , , it will name save the generated vectors , to do that use the saveFAQ/s feature\n"
     ]
    }
   ],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./jamesFAQs/Augmented\")\n",
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./jamesFAQs/Augmented\")\n",
    "\n",
    "# Initialize Bani\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ],assignVectors = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Regenerate questions + Test with augmented FAQs (with training via batchHardTriplet)\n",
    "\"\"\"\n",
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "from Bani.core.defaults import defaultGenerateManager\n",
    "import pandas as pd\n",
    "\n",
    "# babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "# comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "# b_questions , b_answers = extractQA(babyBonusOrignal)  # list of questions and answers \n",
    "# c_questions , c_answers = extractQA(comcareOrignal)    # list of questions and answers \n",
    "# babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "# comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)\n",
    "\n",
    "# babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)\n",
    "# comcareFAQ.buildFAQ(generator = defaultGenerateManager)\n",
    "\n",
    "# babyBonusFAQ.save(\"./jamesFAQs/Augmented\")\n",
    "# comcareFAQ.save(\"./jamesFAQs/Augmented\")\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "# babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "# babyBonusFAQ.load(\"./jamesFAQs/Augmented\")\n",
    "# comcareFAQ = FAQ(\"comcare\")\n",
    "# comcareFAQ.load(\"./jamesFAQs/Augmented\")\n",
    "\n",
    "# # Initialize Bani\n",
    "# bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ])\n",
    "\n",
    "# Do I need to run this?\n",
    "new_model_path= \"./checkpoints/latest_model1\"\n",
    "bot.train(outputPath = new_model_path, lossName = \"batchHardTriplet\", batchSize = 64,epochs=5)\n",
    "\n",
    "# # Prepare test data\n",
    "# df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "# testData = []\n",
    "\n",
    "# for i in range(len(df)):\n",
    "#     orignal = df.loc[i,\"original\"]\n",
    "#     reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "#     testData.append((orignal,reframed))\n",
    "\n",
    "# # Begin test\n",
    "# correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "# print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare test data\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))\n",
    "\n",
    "# Begin test\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning vectors to babyBonus faq , , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "Assigning vectors to comcare faq , , it will name save the generated vectors , to do that use the saveFAQ/s feature\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/james/Projects/Bani/Bani/Bani.py:200: UserWarning: 4 questions in the test set did not match any orignal questions\n",
      "  warnings.warn(\"{} questions in the test set did not match any orignal questions\".format(len(nonMatched)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running test on 290 questions\n",
      "0.903448275862069 with 262 out of 290 questions correct\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test with original FAQs (w/o training)\n",
    "\"\"\"\n",
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "import pandas as pd\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./no_generate\")\n",
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./no_generate\")\n",
    "\n",
    "# Initialize Bani\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)\n",
    "\n",
    "# Do I need to run this?\n",
    "# bot.train(outputPath = \"./checkpoints/dummy\", lossName = \"batchHardTriplet\", batchSize = 64)\n",
    "\n",
    "# Prepare test data\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))\n",
    "\n",
    "# Begin test\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigning vectors to babyBonus faq , , it will name save the generated vectors , to do that use the saveFAQ/s feature\n",
      "Assigning vectors to comcare faq , , it will name save the generated vectors , to do that use the saveFAQ/s feature\n"
     ]
    },
    {
     "ename": "TrainDataInvalid",
     "evalue": "Attempted to use batchHardTriplet loss but label 0 has only 1 exmaples !!! At least 2 required",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mTrainDataInvalid\u001B[0m                          Traceback (most recent call last)",
      "\u001B[0;32m<ipython-input-14-3223ae290813>\u001B[0m in \u001B[0;36m<module>\u001B[0;34m\u001B[0m\n\u001B[1;32m     16\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     17\u001B[0m \u001B[0;31m# Do I need to run this?\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 18\u001B[0;31m \u001B[0mbot\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrain\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0moutputPath\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"./checkpoints/dummy\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mlossName\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;34m\"batchHardTriplet\"\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatchSize\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0;36m64\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     19\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     20\u001B[0m \u001B[0;31m# Prepare test data\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Bani/Bani/Bani.py\u001B[0m in \u001B[0;36mtrain\u001B[0;34m(self, outputPath, batchSize, epochs, lossName, **kwargs)\u001B[0m\n\u001B[1;32m    216\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    217\u001B[0m         \u001B[0;32mfor\u001B[0m \u001B[0mfaq\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFAQs\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m--> 218\u001B[0;31m             \u001B[0mlossInstance\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mLossHandler\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlossName\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mlossName\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mFAQ\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mfaq\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFAQ\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0mbatchSize\u001B[0m\u001B[0;34m=\u001B[0m\u001B[0mbatchSize\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m    219\u001B[0m             \u001B[0mtrainDataloader\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlossInstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainDataLoader\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m    220\u001B[0m             \u001B[0mtrainLoss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlossInstance\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainLoss\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Bani/Bani/modelRelated/lossHandler.py\u001B[0m in \u001B[0;36m__init__\u001B[0;34m(self, lossName, FAQ, model, batchSize)\u001B[0m\n\u001B[1;32m     17\u001B[0m             \u001B[0;32massert\u001B[0m \u001B[0mbatchSize\u001B[0m \u001B[0;34m>\u001B[0m \u001B[0;36m8\u001B[0m \u001B[0;32mand\u001B[0m \u001B[0mbatchSize\u001B[0m\u001B[0;34m%\u001B[0m\u001B[0;36m8\u001B[0m \u001B[0;34m==\u001B[0m \u001B[0;36m0\u001B[0m\u001B[0;34m,\u001B[0m \u001B[0;34m\"needed for the pk sampler (p ,k > 2), must give large batches for batch hard\"\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 19\u001B[0;31m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainExamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mconvertForBatchHardTripletLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mFAQ\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mFAQ\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     20\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mdataset\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mBatchHardDataset\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mexamples\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainExamples\u001B[0m \u001B[0;34m,\u001B[0m \u001B[0mmodel\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     21\u001B[0m             \u001B[0mself\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mtrainLoss\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mlosses\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mBatchHardTripletLoss\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mmodel\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mmodel\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Bani/Bani/modelRelated/utils.py\u001B[0m in \u001B[0;36mconvertForBatchHardTripletLoss\u001B[0;34m(FAQ, minSameLabels)\u001B[0m\n\u001B[1;32m     48\u001B[0m     \"\"\"\n\u001B[1;32m     49\u001B[0m     \u001B[0;32massert\u001B[0m \u001B[0mminSameLabels\u001B[0m \u001B[0;34m>=\u001B[0m \u001B[0;36m2\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 50\u001B[0;31m     \u001B[0mminLabelChecker\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlossName\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0;34m\"batchHardTriplet\"\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mFAQ\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFAQ\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mminSameLabels\u001B[0m\u001B[0;34m=\u001B[0m \u001B[0mminSameLabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     51\u001B[0m     \u001B[0mfaq\u001B[0m \u001B[0;34m=\u001B[0m \u001B[0mFAQ\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mFAQ\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     52\u001B[0m     \u001B[0;31m# now converting\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;32m~/Projects/Bani/Bani/modelRelated/utils.py\u001B[0m in \u001B[0;36mminLabelChecker\u001B[0;34m(lossName, FAQ, minSameLabels)\u001B[0m\n\u001B[1;32m     38\u001B[0m     \u001B[0;32mfor\u001B[0m \u001B[0mL\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcount\u001B[0m \u001B[0;32min\u001B[0m \u001B[0mcounter\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mitems\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     39\u001B[0m         \u001B[0;32mif\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mcount\u001B[0m \u001B[0;34m<\u001B[0m \u001B[0mminSameLabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m:\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0;32m---> 40\u001B[0;31m             \u001B[0;32mraise\u001B[0m \u001B[0mTrainDataInvalid\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0;34m\"Attempted to use {} loss but label {} has only {} exmaples !!! At least {} required\"\u001B[0m\u001B[0;34m.\u001B[0m\u001B[0mformat\u001B[0m\u001B[0;34m(\u001B[0m\u001B[0mlossName\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mL\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mcount\u001B[0m\u001B[0;34m,\u001B[0m\u001B[0mminSameLabels\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m)\u001B[0m\u001B[0;34m\u001B[0m\u001B[0;34m\u001B[0m\u001B[0m\n\u001B[0m\u001B[1;32m     41\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n\u001B[1;32m     42\u001B[0m \u001B[0;34m\u001B[0m\u001B[0m\n",
      "\u001B[0;31mTrainDataInvalid\u001B[0m: Attempted to use batchHardTriplet loss but label 0 has only 1 exmaples !!! At least 2 required"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Test with original FAQs (with training via batchHardTriplet)\n",
    "You cannot perform batchHardTriplet loss training without alternative examples of the same question\n",
    "\"\"\"\n",
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ\n",
    "import pandas as pd\n",
    "\n",
    "# Load FAQs with augmented questions\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./no_generate\")\n",
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./no_generate\")\n",
    "\n",
    "# Initialize Bani\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = True)\n",
    "\n",
    "# Do I need to run this?\n",
    "bot.train(outputPath = \"./checkpoints/dummy\", lossName = \"batchHardTriplet\", batchSize = 64)\n",
    "\n",
    "# Prepare test data\n",
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")\n",
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))\n",
    "\n",
    "# Begin test\n",
    "correct, question_count = bot.test(faqId = 0, testData = testData, K = 3)\n",
    "print(f\"{correct/question_count} with {correct} out of {question_count} questions correct\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}