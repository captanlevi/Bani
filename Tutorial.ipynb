{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install Bani\n",
    "!pip install \n",
    "import sys\n",
    "from typing import List,Tuple,Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nsys.path.append('./')\\nsys.path.append('./core')\\n\""
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# appending paths as this is a jupyter notebook, if you want to use from the source code !!!\n",
    "\"\"\"\n",
    "sys.path.append('./')\n",
    "sys.path.append('./core')\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is optional, we read the data from any faq here\n",
    "In this case we use the orignal faq pickle files , you may use\n",
    "csv or any other format !!!\n",
    "\"\"\"\n",
    "import pickle\n",
    "def save_dict(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dict(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def extractQA(orignalDct):\n",
    "    \"\"\"\n",
    "    Just returns the questions and answers in a list , \n",
    "    NOthing fancy\n",
    "    \"\"\"\n",
    "    q2L = orignalDct[\"question_to_label\"]\n",
    "    a2L = orignalDct[\"answer_to_label\"]\n",
    "    \n",
    "\n",
    "    l2A = dict()\n",
    "    for a,l in a2L.items():\n",
    "        l2A[l] = a\n",
    "\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q,l in q2L.items():\n",
    "        questions.append(q)\n",
    "        answers.append(l2A[l])\n",
    "    return questions , answers\n",
    "    \n",
    "\n",
    "babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "\n",
    "b_questions , b_answers = extractQA(babyBonusOrignal)\n",
    "c_questions , c_answers = extractQA(comcareOrignal)\n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOw the real work starts , We have question answer pairs from \n",
    "baby bonus and comcare , We need to create a new faq for both of them\n",
    "\n",
    "NOTE - This is the starting point , we need a LIst of questions and a list of answers\n",
    "THE LENGTH OF BOTH LIST MUST BE SAME\n",
    "if two questions answer the same questions then just copy the answer \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# first we convert the questions and answers to \n",
    "babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Until this point we only have the orignal questions and answers in the faq\n",
    "We now need to do two things\n",
    "1) generate questions using pipelined\n",
    "2) assign vectors to the questions using a model  \n",
    "\n",
    "\n",
    "you can use your own generation pipeline , or use the default pipeline provided !!!\n",
    "if you choose to implement your own pipeline make sure that your class implements at least one of \n",
    "batch_generate or exact_batch_generate methods\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an example of creating your own GenerateManager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from Bani.core.generation import GenerateManager\n",
    "\n",
    "class MyProducer1:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "class MyProducer2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "    \n",
    "names = [\"myProducer1_name\", \"myProducer2_name\"]\n",
    "toGenerate = [3,5] # At max generate 3 for first producer and 5 for second\n",
    "producers = [MyProducer1(), MyProducer2()]\n",
    "\n",
    "\n",
    "myGenerateManager = GenerateManager(producers = producers , names = names , nums = toGenerate)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n",
      "Initializing spaCy model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 291/291 [00:26<00:00, 11.02it/s]\n",
      "  0%|                                                                                          | 0/291 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 291/291 [04:00<00:00,  1.21it/s]\n",
      " 11%|████████▌                                                                       | 31/291 [00:00<00:00, 303.94it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 291/291 [00:00<00:00, 380.31it/s]\n",
      "  0%|                                                                                          | 0/291 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 291/291 [04:38<00:00,  1.05it/s]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Now we will build the FAQ using the generationManager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [01:28<00:00,  3.27it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [05:05<00:00,  1.06s/it]\n",
      " 11%|████████▉                                                                       | 32/288 [00:00<00:00, 319.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 288/288 [00:00<00:00, 295.96it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [04:32<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "comcareFAQ.buildFAQ(generator  = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can save the FAQ at any time we want !! , just pass the path to the root dir \n",
    "\"\"\"\n",
    "babyBonusFAQ.save(\"./faqStore\")\n",
    "comcareFAQ.save(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The saved FAQ can be easily loaded \n",
    "\"\"\"\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OverWritting the vectors of FAQ named babyBonus\n",
      "OverWritting the vectors of FAQ named comcare\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lets now take a look at the bot part\n",
    "\"\"\"\n",
    "bot = Bani(modelPath = \"./bani/checkpoints/dummy\" , FAQs =[babyBonusFAQ, comcareFAQ]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can also save the FAQ again to preserve the assigned vectors ,\n",
    "The next time you load these FAQs with the bot the vectors will not be reassigned ,\n",
    "You need to clear the assigned vectors if you want to reassign\n",
    "\"\"\"\n",
    "bot.saveFAQs(\"./faqStore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = bot.findClosest(\"what is comcare scheme?\", K = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'What is ComCare?'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out[0].question.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.findClosestFromFAQ(1,\"What is comcare?\", K = 1, topSimilar= 5).answer.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "09ad60c4d12941309b47fb0e3289cfd7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Epoch', max=1.0, style=ProgressStyle(description_width='i…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b3aeafc48d64be0b2b8d09874b920cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Iteration', max=209.0, style=ProgressStyle(description_wi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "bot.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "bot.saveModel(\"./bani/checkpoints/dummy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
