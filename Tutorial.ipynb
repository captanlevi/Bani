{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install Bani\n",
    "python -m spacy download en_core_web_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from Bani.Bani import Bani\n",
    "from Bani.core.FAQ import FAQ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This cell is optional, we read the data from any faq here\n",
    "In this case we use the orignal faq pickle files , you may use\n",
    "csv or any other format !!!\n",
    "\n",
    "\n",
    "THE goal here is to get a list of questions and corosponding answers\n",
    "\"\"\"\n",
    "import pickle\n",
    "def save_dict(obj, path):\n",
    "    with open(path, 'wb') as f:\n",
    "        pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
    "\n",
    "def load_dict(path):\n",
    "    with open(path, 'rb') as f:\n",
    "        return pickle.load(f)\n",
    "    \n",
    "def extractQA(orignalDct):\n",
    "    \"\"\"\n",
    "    Just returns the questions and answers in a list , \n",
    "    NOthing fancy\n",
    "    \"\"\"\n",
    "    q2L = orignalDct[\"question_to_label\"]\n",
    "    a2L = orignalDct[\"answer_to_label\"]\n",
    "    \n",
    "\n",
    "    l2A = dict()\n",
    "    for a,l in a2L.items():\n",
    "        l2A[l] = a\n",
    "\n",
    "\n",
    "    questions = []\n",
    "    answers = []\n",
    "\n",
    "    for q,l in q2L.items():\n",
    "        questions.append(q)\n",
    "        answers.append(l2A[l])\n",
    "    return questions , answers\n",
    "    \n",
    "\n",
    "babyBonusOrignal = load_dict(\"./tutorialFAQs/baby_bonus_orignal.pkl\") \n",
    "comcareOrignal =  load_dict(\"./tutorialFAQs/comcare_orignal.pkl\")\n",
    "\n",
    "\n",
    "b_questions , b_answers = extractQA(babyBonusOrignal)  # list of questions and answers \n",
    "c_questions , c_answers = extractQA(comcareOrignal)    # list of questions and answers \n",
    "\n",
    "\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "NOw the real work starts , We have question answer pairs from \n",
    "baby bonus and comcare , We need to create a new faq for both of them\n",
    "\n",
    "NOTE - This is the starting point , we need a LIst of questions and a list of answers\n",
    "THE LENGTH OF BOTH LIST MUST BE SAME\n",
    "if two questions answer the same questions then just copy the answer \n",
    "\"\"\"\n",
    "\n",
    "\n",
    "# first we convert the questions and answers to FAQs\n",
    "babyBonusFAQ = FAQ(name = \"babyBonus\",questions = b_questions, answers = b_answers)\n",
    "comcareFAQ = FAQ(name = \"comcare\", questions = c_questions , answers = c_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
      "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
      "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForMaskedLM were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['cls.predictions.decoder.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Until this point we only have the orignal questions and answers in the faq\n",
    "We now need to do two things\n",
    "1) generate questions using pipelined\n",
    "2) assign vectors to the questions using a model  \n",
    "\n",
    "\n",
    "you can use your own generation pipeline , or use the default pipeline provided !!!\n",
    "if you choose to implement your own pipeline make sure that your class implements at least one of \n",
    "batch_generate or exact_batch_generate methods\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "from Bani.core.defaults import defaultGenerateManager\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This is an example of creating your own GenerateManager\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "from Bani.core.generation import GenerateManager\n",
    "\n",
    "class MyProducer1:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "class MyProducer2:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def batch_generate(questions : List[str]) -> Dict[str, List[str]]:\n",
    "        \"\"\"\n",
    "        Takes list of questions and returns a dict , with each question \n",
    "        mapped to the list of generated questions\n",
    "        \"\"\"\n",
    "        \n",
    "        resultDict = dict()\n",
    "        for question in questions:\n",
    "            resultDict[question] = [\"generated1\", \"generated2\", \"and so on\"]\n",
    "        \n",
    "        return resultDict\n",
    "    \n",
    "    \n",
    "names = [\"myProducer1_name\", \"myProducer2_name\"]\n",
    "toGenerate = [3,5] # At max generate 3 for first producer and 5 for second\n",
    "producers = [MyProducer1(), MyProducer2()]\n",
    "\n",
    "\n",
    "myGenerateManager = GenerateManager(producers = producers , names = names , nums = toGenerate)\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with IdentityProducer pipeline\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Now we will build the FAQ using the generationManager\n",
    "This will generate paraphrases of the questions using the pipeline given\n",
    "\n",
    "you can also leave the generator argument as none ,\n",
    "In this case you wont be generating any questions, but then you cant train using a \n",
    "batch hard triple loss as well !!!\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "babyBonusFAQ.buildFAQ(generator = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with SymSub pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [01:28<00:00,  3.27it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with FPM pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [05:05<00:00,  1.06s/it]\n",
      " 11%|████████▉                                                                       | 32/288 [00:00<00:00, 319.87it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with EDA pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 288/288 [00:00<00:00, 295.96it/s]\n",
      "  0%|                                                                                          | 0/288 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working with nlpAug pipeline\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████████████████████████████| 288/288 [04:32<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "comcareFAQ.buildFAQ(generator  = defaultGenerateManager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Now we can save the FAQ at any time we want !! , just pass the path to the root dir \n",
    "\"\"\"\n",
    "babyBonusFAQ.save(\"./faqStore\")\n",
    "comcareFAQ.save(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "The saved FAQ can be easily loaded \n",
    "\"\"\"\n",
    "babyBonusFAQ = FAQ(\"babyBonus\")\n",
    "babyBonusFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "comcareFAQ = FAQ(\"comcare\")\n",
    "comcareFAQ.load(\"./faqStore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rjkin\\Desktop\\BaniPackage\\Bani\\Bani.py:131: UserWarning: Vectors already assigned to babyBonus FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\n",
      "  warnings.warn(\"Vectors already assigned to {} FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\".format(faq.name))\n",
      "C:\\Users\\rjkin\\Desktop\\BaniPackage\\Bani\\Bani.py:131: UserWarning: Vectors already assigned to comcare FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\n",
      "  warnings.warn(\"Vectors already assigned to {} FAQ , if you want to reassign using the current model please clear the vectors using resetAssigned vectors\".format(faq.name))\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Lets now take a look at the bot part, for assignVectors refer to the readme\n",
    "\"\"\"\n",
    "bot = Bani(modelPath = None , FAQs =[babyBonusFAQ, comcareFAQ], assignVectors = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "We can also save the FAQ again to preserve the assigned vectors ,\n",
    "The next time you load these FAQs with the bot the vectors will not be reassigned ,\n",
    "You need to clear the assigned vectors if you want to reassign\n",
    "\"\"\"\n",
    "bot.saveFAQs(\"./faqStore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "out is a list of FAQ output , each output for each FAQ\n",
    "compare the score field in each to get the highest scored FAQ, \n",
    "you can also set a margin of error and ask the user to decide between the faq\n",
    "\n",
    "\"\"\"\n",
    "out = bot.findClosest(\"what is comcare scheme?\", K = 5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<Bani.core.FAQ.FAQOutput at 0x1c02b7340f0>,\n",
       " <Bani.core.FAQ.FAQOutput at 0x1c02b734c18>]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 comcare\n"
     ]
    }
   ],
   "source": [
    "print(out.faqId, out.faqName)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Finding answer from a specific FAQ\n",
    "\"\"\"\n",
    "out = bot.findClosestFromFAQ(1,\"eligliblity for baby bonus for my child?\", K = 3, topSimilar= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "faqName - comcare\n",
      "\n",
      "answer - If your child is an existing beneficiary and is eligible to receive Education Bursary (cash), if your child is a: Preschool student – you will need to submit supporting documents to MSF within the same calendar year. Primary/Secondary/Pre-U/JC student – you do not need to provide supporting documents. MSF will notify you by end April. ITE/Polytechnic student – you do not need to provide supporting documents. MSF will notify you by end July University student – you do not need to provide supporting documents. MSF will notify you by end October.\n",
      "\n",
      "question - When do I receive my Education Bursary (cash) annually?\n",
      "\n",
      "maxScore - 0.3062390089035034\n",
      "\n",
      "score - 0.3062390089035034\n",
      "\n",
      "==================================================\n",
      "\n",
      "[\"Can I get help with my child's student care fees?\", 'Can ComCare provide me with hard cash?', 'How can I qualify for Student Care Fee Assistance?', 'How long does it take for the Student Care Fee Assistance to be processed?', 'Can I get financial assistance if I cannot afford Student Care Centre fees?']\n"
     ]
    }
   ],
   "source": [
    "print(out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nTraining\\n'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "Training\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Error softmaxLayerLos1s loss not supported , supported losses are ('batchHardTriplet', 'contrastiveLoss', 'tripletLoss', 'softmaxLayerLoss')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-37-819ac66471ee>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mlosses\u001b[0m \u001b[0mavailable\u001b[0m \u001b[0mare\u001b[0m \u001b[0mbatchHardTriplet\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontrastiveLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \"\"\"\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mbot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"./checkpoints/dummy\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossName\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"softmaxLayerLos1s\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Desktop\\BaniPackage\\Bani\\Bani.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(self, outputPath, batchSize, epochs, lossName, **kwargs)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    233\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mfaq\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAQs\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 234\u001b[1;33m             \u001b[0mlossInstance\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mLossHandler\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlossName\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mlossName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFAQ\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfaq\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mFAQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mbatchSize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    235\u001b[0m             \u001b[0mtrainDataloader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossInstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainDataLoader\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    236\u001b[0m             \u001b[0mtrainLoss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlossInstance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrainLoss\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Desktop\\BaniPackage\\Bani\\modelRelated\\lossHandler.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, lossName, FAQ, model, batchSize)\u001b[0m\n\u001b[0;32m     12\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlossName\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFAQ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatchSize\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m         \u001b[0msupportedLosses\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;34m\"batchHardTriplet\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"contrastiveLoss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"tripletLoss\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"softmaxLayerLoss\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0mlossName\u001b[0m \u001b[1;32min\u001b[0m \u001b[0msupportedLosses\u001b[0m  \u001b[1;33m,\u001b[0m \u001b[1;34m\"Error {} loss not supported , supported losses are {}\"\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlossName\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msupportedLosses\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;32mif\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlossName\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0msupportedLosses\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: Error softmaxLayerLos1s loss not supported , supported losses are ('batchHardTriplet', 'contrastiveLoss', 'tripletLoss', 'softmaxLayerLoss')"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Look at the documentation for train , and set all the arguments accordingly,\n",
    "if you have not run the buildFAQ , then you cannot train on most of the losses !!! \n",
    "losses available are batchHardTriplet and contrastiveLoss\n",
    "\"\"\"\n",
    "bot.train(\"./checkpoints/dummy\", lossName = \"softmaxLayerLos1s\", batchSize = 8, warmst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Testing\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"./tutorialFAQs/babybonusTest.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testData = []\n",
    "\n",
    "for i in range(len(df)):\n",
    "    orignal = df.loc[i,\"original\"]\n",
    "    reframed = df.loc[i,\"reframed\"]\n",
    "    \n",
    "    testData.append((orignal,reframed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "testing requires a list of (question , reframed_question) to be passed and returns the accuracy score \n",
    "you can test one faq at a time\n",
    "\"\"\"\n",
    "bot.test(faqId = 0, testData = testData, K = 3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
